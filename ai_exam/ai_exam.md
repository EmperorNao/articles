
# Экзамен по "Основы ИИ"


# Список тем

1. История развития ИИ
2. Алгоритм отжига
3. Теория адаптивного резонанса: алгоритмы кластеризации. ART-1
4. Муравьиный алгоритм
5. Нейронные сети
6. Генетический алгоритм
7. Продукционная модель знаний
8. Семантические сети
9. Фреймы
10. Задачи


## 1. История развития ИИ

Искусственный интеллект (ИИ) – это отрасль науки, официально увидевшая свет в 1956 году на летнем семинаре в Дартмут-колледже (Хановер, США), который организовали четверо американских ученых: Джон Мак-Карти, Марвин Мински, Натаниэль Рочестер и Клод Шеннон.

ИИ изначально представлял собой область науки, занимающейся компьютерным моделированием различных способностей интеллекта, идет ли речь об интеллекте человеческом, животном, растительном, социальном или филогенетическом. В основе этой научной дисциплины лежит предположение о том, что все когнитивные функции, как то обучение, мышление, расчет, восприятие, память, даже научное открытие или художественное творчество, могут быть описаны с точностью, дающей возможность запрограммировать компьютер на их воспроизведение.

1. Период пророчеств

    Поначалу, под влиянием первых успехов, исследователи позволяли себе несколько опрометчивые заявления, которые впоследствии неоднократно ставились им в упрек. Так, например, в 1958 году американец Герберт Саймон, позже ставший лауреатом Нобелевской премии по экономике, заявил, что если бы машины допускались к международным соревнованиям, то в ближайшие десять лет они стали бы чемпионами мира по шахматам. 

2. Мрачные времена

    Прогресс замедлился в середине 1960-х годов. В 1966 году в докладе, подготовленном по заказу Сената Соединенных Штатов Америки, говорилось о внутренних ограничениях, присущих машинному переводу. Около десяти лет пресса отзывалась об ИИ неодобрительно.

3. Семантический ИИ

    Исследования не прекратились, но пошли в новых направлениях. Ученые заинтересовались психологией памяти, механизмами понимания, которые они пытались имитировать на компьютере, и ролью знаний в мыслительном процессе. Это привело к появлению значительно развившихся в середине 1970-х годов методов семантического представления знаний, а также к созданию экспертных систем, названных так потому, что для воспроизведения мыслительных процессов в них использовались знания квалифицированных специалистов. В начале 1980-х годов на экспертные системы возлагались большие надежды в связи с широкими возможностями их применения, например, для медицинской диагностики.

4. Неоконнекционизм и машинное обучение

    Технические усовершенствования позволили разработать алгоритмы машинного обучения (Machine Learning), благодаря которым компьютеры смогли накапливать знания и автоматически перепрограммироваться на основе собственного опыта.

5. От ИИ до интерфейсов «человек – машина»

    С конца 1990-х годов ИИ стали объединять с робототехникой и интерфейсом «человек – машина» с целью создания интеллектуальных агентов, предполагающих наличие чувств и эмоций. Это привело, среди прочего, к появлению нового исследовательского направления – аффективных (или эмоциональных) вычислений (affective computing), направленных на анализ реакций субъекта, ощущающего эмоции, и их воспроизведение на машине, и позволило усовершенствовать диалоговые системы (чат-боты).

6. Возрождение ИИ

    С 2010 года мощность компьютеров позволяет сочетать так называемые большие данные (Big Data) с методами глубокого обучения (Deep Learning), которые основываются на использовании искусственных нейронных сетей. Весьма успешное применение во многих областях (распознавание речи и изображений, понимание естественного языка, беспилотный автомобиль и т.д.) позволяет говорить о возрождении ИИ.

 

## 2. Алгоритм отжига

Оптимизационный алгоритм. Заключается в итеративном поиске лучших параметров через случайное блуждание в сужающемся (относительно вероятности) пространстве, являющемся подпространством исходного решения.

Генерируем начальное решение и оцениваем его качество - назовём эту оценку качества энергией. Наилучшим решением будет решение с наименьшей энергией.

Также, инициализируем параметры температуры - которым определяется вероятностное подпространство в пространстве всех исходных решений.
Чем больше параметр температуры T - тем больше пространство поиска нового решения.

Внутри одной итерации, будем k раз повторять следующую последовательность действий: 

1. Случайным образом изменить текущее решение (желательно)
2. Оценка энергии 
3. Если новое решение имеет меньшую энергию E чем текущую, то заменим его. Если же оно имеет большую энергию, то проверим его по критерию допуска. 
Сгенерируем случайную переменную 0 <= p_g <= 1. Если данное p_g меньше чем условие допуска p(deltaЕ) = exp(-deltaE/T), то заменим текущее решение даже если его энергия больше.
Будем также запоминать лучшее полученное решение.


Таким образом, внутри итераций мы пытаемся найти какое-то лучшее решение не только из жадных с помощью случайных блужданий.

После каждой итерации будем уменьшать температуру по заданному правилу. Будем продолжать итерации до тех пор, пока лучшая энергия не станет меньше или равной минимальной, либо пока температура не станет меньше минимальной.

Основные параметры - количество внутренних итераций, способ уменьшения температуры, минимальная температура.



## 3. Теория адаптивного резонанса: алгоритмы кластеризации. ART-1

Основная идея заключается в том, что распознавание образов является результатом нисходящих ожиданий и восходящей сенсорной информации. Причем нисходящие ожидания принимают форму припоминаемых прототипов или образцов, которые затем сравниваются с реально наблюдаемыми свойствами объекта. Это сравнение лежит в основании меры категориальной принадлежности. Когда разница между ожиданием и наблюдаемым не превышает определенный порог («бдительность») наблюдаемый объект считается принадлежащим к определенной категории. Таким образом система предлагает решение проблемы пластичности/стабильности, то есть проблемы приобретения нового знания без нарушения уже существующего.

ART-1 является алгоритмом кластеризации и работает только с объектами с бинарным описанием.

На входе принимает вектора объектов для кластеризации.

Параметры:
- N - максимальное количество прототипов.
- d - размер вектора
- b - небольшое число
- p - параметр внимания (принадлежит от 0 до 1)


Будем по очереди определять каждый вектор к одному из заданных прототипов.

Принадлежность к кластеру определяется следующим правилом (P - прототип, E - объект):

|P and E| / (b + |P|) > |E| / (b + d)

Если принадлежность кластеру пройдена, то далее проходится тест на внимательность:

|P and E| / |E| > p

При прохождении всех тестов, вектор прототип кластера обновляется по правилу 

P = P and E

и вектор добавляется в заданный кластер. Если же для данного вектора не находится подходящего кластера, то создадим новый на его основе.


## 4. Муравьиный алгоритм

Оптимизационный алгоритм, основанный на физическом поведении муравьёв.

Муравьиный алгоритм хорошо подходит для алгоритмов поиска оптимального пути.

В каждый момент перехода по графу, муравей выбирает с некой вероятностью одну из следующих вершин, которую он не посетил.
Эта вероятность выражается как p = t(r, u)^a * h(r, u)^b / sum_near_v(t(r, near_v)^a * h(r, near_v)^b)

t(r, u) - интенсивность фермента на ребре, h(r, u) - длина ребра.
a - вес фермента, b - вес длины ребра.

Посетив все вершины по одной, муравей узнаёт длину своего пути. На каждой грани было оставлено D_ij = Q/L фермента.

Q - константа, L - длина пути.

Обновление ферментов происходит по формуле 

t_ij = D_ij + r * t_IJ

r - ещё один параметр, принадлежит от 0 до 1.

Для удаление неэффективных путей - используется испарение фермента. 

t_ij = t_ij * (1 - r).


Алгоритм применяется для нескольких муравьёв одновременно. Затем они обновляют ферменты, происходит испарение.
Алгоритм повторяется до некого условия остановки. 

Затем определяется лучший путь.


## 5. Нейронные сети

### ИНС
ИНС - произведение матриц с последовательным применением функций активации.

### Однослойный персептрон
Однослойный персептрон - на входе вектор x размерности 1xN. Обладаем матрицей весов W размера 1xN.
Производим операцию <W, x^T> скалярного произведения (сумматор), далее к полученному числу применяем функцию активации F (обычно нелинейную).


### Обучение нейрона по правилу Хебба
Первое правило Хебба — Если сигнал персептрона неверен и равен нулю, то необходимо увеличить веса тех входов, на которые была подана единица.

Второе правило Хебба — Если сигнал персептрона неверен и равен единице, то необходимо уменьшить веса тех входов, на которые была подана единица.


## 6. Генетический алгоритм
При  описании  генетических  алгоритмов  используются  определения,  заимствованные из генетики. Например, речь идет о популяции особей, а в качестве  базовых понятий применяются ген, хромосома, генотип, фенотип, аллель. 
Также  используются  соответствующие  этим  терминам  определения  из  технического  лексикона, в частности, цепь, двоичная последовательность, структура. 

Популяция - это конечное множество особей.  Особи, входящие в популяцию, в генетических алгоритмах представляются  хромосомами с закодированным в них множествами параметров задачи, т.е. решений,  которые иначе называются точками в пространстве поиска (search points). В  некоторых работах особи называются организмами.  

Хромосомы (другие названия - цепочки или кодовые последовательности) - это  упорядоченные последовательности генов.  

Ген (также называемый свойством, знаком или детектором) - это атомарный  элемент генотипа, в частности, хромосомы.  

Генотип или структура - это набор хромосом данной особи. Следовательно,  особями популяции могут быть генотипы либо единичные хромосомы (в довольно  распространенном случае, когда генотип состоит из одной хромосомы).  

Фенотип - это набор значений, соответствующих данному генотипу, т.е.  декодированная структура или множество параметров задачи {решение, точка  пространства поиска).  

Аллель - это значение конкретного гена, также определяемое как значение  свойства или вариант свойства.  

Локус или позиция указывает место размещения данного гена в хромосоме (цепочке). Множество позиций генов - это локи.

Очень важным понятием в генетических алгоритмах считается  приспособленности (fitness  function),  иначе  называемая  функцией  функция  оценки - функция потерь.

#### Оператор скрещивания.
Например берём 1.. k генов и k.. второго для первого потомка (k - случайное число), потом наоборот для второго потомка.

#### Оператор мутации
Например меняем порядок/значение генов

Работает как и отжиг на случайном блуждании.

Генерируем начальную популяцию, далее считаем оценку каждой особи. Используем скрещивание и генерируем новые особи. Далее используем мутации.
Делаем новую оценку. Повторяем до условия остановки.


## 7. Продукционная модель знаний
Продукционная модель знаний - модель, основанная на правилах. Знания представляются в виде предложений
«Если (условие), то (действие)».

Под условием понимается некоторое предложение — образец, по ко­то­рому осуществляется поиск в базе знаний, а под действием — действия, выполняемые при успешном исходе поиска (они могут быть про­ме­жу­точ­ными, выступающими далее как условия, и терминальными или целевыми, завершающими работу системы).

При использовании продукционной модели база знаний состоит из набора правил, Программа, управляющая перебором правил, называется машиной вывода. Чаще всего вывод бывает прямой (от данных к поиску цели) или обратный (от цели для ее подтверждения – к данным). Данные — это исходные факты, на основании которых запускается маши­на вывода.

Если в памяти системы хранится некоторый набор продукций, то они об­ра­зуют систему продукций. В системе продукций должны быть заданы спе­ци­альные процедуры управления продукциями, с помощью которых происходит актуализация продукций и выполнение той или иной про­дук­ции из числа ак­ту­а­ли­зированных.

### Архитектура систем, основанных на правилах
В состав системы продукций входит база правил (продукций), глобальная база данных и система управления или процессор логического вывода. База правил – это область памяти, которая содержит совокупность знаний в форме правил вида ЕСЛИ – ТО.

Глобальная база данных — область памяти, содержащая факти­чес­кие данные (факты). Система управления формирует заключения, ис­поль­зуя базу пра­вил и базу данных. Существуют следующие способы форми­ро­ва­ния за­клю­че­ний — прямые и обратные выводы.

Правила вывода бывает удобно представлять в виде дерева решений. 

### Механизмы вывода в системах, основанных на правила

В прямых выводах выбирается один из элементов данных, содержащихся в базе данных, и если при сопоставлении этот элемент согласуется с левой частью правила (посылкой), то из правила выводится соответствующее за­клю­че­ние и помещается в базу данных или исполняется действие, определяемое пра­вилом, и соответствующим образом изменяется содержимое базы данных.

В обратных выводах процесс начинается от поставленной це­ли. Если эта цель согласуется с правой частью правила (заключением), то посылка правила принимается за подцель или гипотезу. Этот процесс повторяется до тех пор, пока не будет получено совпадение подцели с данными.

Продукционная модель привлекает разработчиков своей нагляд­ностью, высокой модульностью, легкостью внесения дополнений и из­ме­не­ний и простотой механизма логического вывода.

Сильные стороны систем продукций:

- модульность;
- единообразие структуры (основные компоненты продукционной системы могут применяться для построения интеллектуальных сис­тем с различной проблемной ориентацией);
- естественность (вывод заключения в продукционной системе во мно­гом аналогичен процессу рассуждения эксперта);
- гибкость родовидовой иерархии понятий, которая поддер­жи­ва­ет­ся только как связь между правилами (изменение правила ведет за собой изменение в иерархии);
- простота создания и понимания отдельных правил;
- простота пополнения и модификации;
- простота механизма логического вывода. 

- Слабые стороны систем продукций:
- процесс вывода менее эффективен, чем в других системах, поскольку большая часть времени при выводе затрачивается на непроизводительную проверку применимости правил;
- сложно представить родовидовую иерархию понятий;
- неясность взаимных отношений правил;
- сложность оценки целостного образа знаний;
- отличие от человеческой структуры знаний;
- отсутствие гибкости в логическом выводе.

Представление знаний с помощью продукций иногда называют «плоским», так как в продукционных системах отсутствуют средства для установления иерархий правил. Объем знаний продукционных систем растет линейно, по мере включения в нее новых фрагментов знаний, в то время как в традиционных алгоритмических системах, использующих деревья решений, зависимость между объемом база знаний и количеством знаний является логарифмической.


## 8. Семантические сети
Семантическая сеть (Semantic network) — информационная модель предметной области, имеющая вид ориентированного графа, вершины которого соответствуют объектам предметной области, а дуги (рёбра) задают отношения между ними. Объектами могут быть понятия, события, свойства, процессы. Таким образом, семантическая сеть является одним из способов представления знаний. В названии соединены термины из двух наук: семантика в языкознании изучает смысл единиц языка, а сеть в математике представляет собой разновидность графа — набора вершин, соединённых дугами (рёбрами), которым присвоено некоторое число. В семантической сети роль вершин выполняют понятия базы знаний, а дуги (причем направленные) задают отношения между ними. Таким образом, семантическая сеть отражает семантику предметной области в виде понятий и отношений.

Для всех семантических сетей справедливо разделение по арности и количеству типов отношений.

##### По количеству типов отношений, сети могут быть однородными и неоднородными.

- Однородные сети обладают только одним типом отношений (стрелок), например, таковой является вышеупомянутая классификация биологических видов (с единственным отношением AKO).
- В неоднородных сетях количество типов отношений больше одного. Классические иллюстрации данной модели представления знаний представляют именно такие сети. Неоднородные сети представляют больший интерес для практических целей, но и большую сложность для исследования. Неоднородные сети можно представлять как переплетение древовидных многослойных структур. Примером такой сети может быть Семантическая сеть Википедии.

##### По арности:
- типичными являются сети с бинарными отношениями (связывающими ровно два понятия). Бинарные отношения очень просты и удобно изображаются на графе в виде стрелки между двух концептов. Кроме того, они играют исключительную роль в математике.
- На практике, однако, могут понадобиться отношения, связывающие более двух объектов — N-арные. При этом возникает сложность — как изобразить подобную связь на графе, чтобы не запутаться. Концептуальные графы (см. ниже) снимают это затруднение, представляя каждое отношение в виде отдельного узла.

##### По размеру:
- Для решения конкретных задач, например, тех, которые решают системы искусственного интеллекта.
- Семантическая сеть отраслевого масштаба должна служить базой для создания конкретных систем, не претендуя на всеобщее значение.
- Глобальная семантическая сеть. Теоретически такая сеть должна существовать, поскольку всё в мире взаимосвязано. Возможно, когда-нибудь такой сетью станет Всемирная паутина.

#### Семантические отношения
Количество типов отношений в семантической сети определяется её создателем, исходя из конкретных целей. В реальном мире их число стремится к бесконечности. Каждое отношение является, по сути, предикатом, простым или составным. Скорость работы с базой знаний зависит от того, насколько эффективно реализованы программы обработки нужных отношений:

- Иерархические

  Наиболее часто возникает потребность в описании отношений между элементами, множествами и частями объектов. Отношение между объектом и множеством, обозначающим, что объект принадлежит этому множеству, называется отношением классификации

  - Отношение между надмножеством и подмножеством
  - Объект, как правило, состоит из нескольких частей, или элементо/

- Вспомогательные
  В семантических сетях часто используются также следующие отношения[источник не указан 961 день]:

  - функциональные связи (определяемые обычно глаголами «производит», «влияет»…);
  - количественные (больше, меньше, равно…);
  - пространственные (далеко от, близко от, за, под, над…);
  - временные (раньше, позже, в течение…);
  - атрибутивные (иметь свойство, иметь значение);
  - логические (И, ИЛИ, НЕ);
  - лингвистические.

    
#### Представление событий в нотации семантических сетей

Делаем каузальную сеть

#### Достоинства семантических сетей:
- универсальность, достигаемая за счет выбора соответствующего набора отношений. В принципе с помощью семантической сети можно описать сколь угодно сложную ситуацию, факт или предметную область;
- наглядность системы знаний, представленной графически;
- близость структуры сети, представляющей систему знаний, семантической структуре фраз на естественном языке;
- соответствие современным представлениям об организации долговременной памяти человека.

#### Недостатки семантических сетей:
- сетевая модель не дает (точнее, не содержит) ясного представления о структуре предметной области, поэтому формирование и модификация такой модели затруднительны;
- сетевые модели представляют собой пассивные структуры, для обработки которых необходим специальный аппарат формального вывода;
- проблема поиска решения в семантической сети сводится к задаче поиска фрагмента сети, соответствующего подсети, отражающей поставленный запрос. Это, в свою очередь, обуславливает сложность поиска решения в семантических сетях;
- представление, использование и модификация знаний при описании систем реального уровня сложности оказывается трудоемкой процедурой, особенно при наличии множественных отношений между ее понятиями.

#### Вывод в семантической модели

Отличительной особенностью экспертных систем, основанных на семантической модели знаний, является невозможность отделить базу знаний от механизма логического вывода. Механизм вывода в такой экспертной системе заложен в саму семантическую сеть и реализуется механизмом наследования. Например, конкретные объекты наследуют все свойства обобщенного объекта. Наследование обладает свойством транзитивности, что позволяет сжимать базу знаний

Можно выделить четыре основных метода логического вывода, которые реализуются в семантической сети.

1. Механизм наследования со свойством транзитивности.
2. Вывод, основанный на базовых операциях.
   К базовым операциям относятся:

    • поиск вершины или ребра по имени;

    • переход от одной вершины к другой по связям.

   Цель базовых операций - найти вершину с заданными свойствами или найти свойства заданной вершины.

3. Вывод, основанный на сопоставлении с образцом.
4. Вывод, основанный на присоединенных процедурах.


## 9. Фреймы

Фреймом называется формализованная модель для отобра­же­ния образа.

В качестве идентификатора фрейму присваивается имя фрей­ма. Это имя должно быть единственным во всей фреймовой системе.

Фрейм имеет определенную внутреннюю структуру, состоящую из мно­­жества элементов, называемых слотами, которым также присва­и­ва­ют­ся имена. За слотами следуют шпации, в которые помещают данные, представляющие текущие значения слотов. Каждый слот в свою очередь представляется опре­де­ленной струк­турой данных. В значение слота подставляется конкретная инфор­ма­ция, относящаяся к объекту, описываемому этим фреймом.

Структуру фрейма можно представить так:

    ИМЯ ФРЕЙМА:
    
    (имя 1-го слота: значение 1-го слота),
    
    (имя 2-го слота: значение 2-го слота),
    
    - - - -
    
    (имя N-го слота: значение N-гo слота).

Слоты:

    Имя слота
    значение слота
    способ получения значения
    присоединённая процедура

Модель фрейма является достаточно универсальной, поскольку позволяет отобразить все многообразие знаний о мире:
- через фреймы-структуры, для обозначения объектов и понятий (заем, залог, вексель);
- через фреймы-роли (менеджер, кассир, клиент);
- через фреймы-сценарии (банкротство, собрание акционеров, празднование именин);
- через фреймы-ситуации (тревога, авария, рабочий режим устройства) и др.

Важнейшим свойством теории фреймов является заимствованное из теории семантических сетей наследование свойств. И во фреймах, и в се­ман­тических сетях наследование происходит по AKO-связям (A-Kind-Of = это). Слот АКО указывает на фрейм более высокого уровня иерархии, от­ку­да неявно наследуются, то есть переносятся, значения аналогичных сло­тов.

Значением слота может быть практически что угодно: числа, фор­му­лы, тексты на естественном языке или программы, правила вы­вода или ссыл­ки на дру­гие слоты данного фрейма или других фрей­мов. В качестве зна­чения слота мо­жет выступать набор слотов бо­лее низкого уровня, что позво­ляет ре­али­зо­вы­вать во фреймовых пред­став­лениях «принцип мат­реш­ки». Связи между фреймами задаются значениями специального сло­та с име­­нем «Связь».

Указатели наследования. Они показывают, какую информацию об атрибутах слотов из фрейма верхнего уровня наследуют слоты с аналогичными именами в данном фрейме. Указатели наследования характерны для фреймовых систем иерархического типа, основанных на отношениях типа «абстрактное — конкретное». В конкретных системах указатели наследования могут быть организованы различными способами и иметь разные обозначения:

    U (Unique) — значение слота не наследуется;
    
    S (Same) — значение слота наследуется;
    
    R (Range) — значения слота должны находиться в пределах интервала значений, указанных в одноименном слоте родительского фрейма;
    
    O (Override) — при отсутствии значения в текущем слоте оно наследуется из фрейма верхнего уровня, однако в случае определения значения текущего слота оно может быть уникальным. Этот тип указателя выполняет одновременно функции указателей U и S.

#### Организация логического вывода во фреймовой системе

В экспертных системах, основанных на фреймах, база знаний представляется совокупностью фреймов-описаний. Рабочая память - совокупностью фреймов-экземпляров. Наличие иерархических связей позволяет, в рамках фреймовой системы, организовывать логический вывод, используя свойство транзитивности.

Поддерживаются следующие методы логического вывода:

- эстафета присоединенных процедур. Процедуры автоматически запускаются при обращении к соответствующему слоту;
- использование наследования. Наследование основывается на использовании отношения «абстрактное - конкретное»;
- использование значений по умолчанию.


#### Преимущества фреймового подхода
1. Возможность описывать и хранить иерархию понятий в базе знаний в явной форме.
2. Принцип наследования позволяет строить компактные и наглядные базы знаний, а также выдавать решения при отсутствии ряда деталей.
3. Универсальность модели позволяет отобразить всё многообразие знаний о реальном мире.
4. С помощью присоединенных процедур может быть реализован любой механизм управления логическим выводом. 

#### Недостатки фреймового подхода
1. Для реальных задач фреймовые структуры оказываются достаточно сложными в организации, что влечет за собой снижение скорости работы механизмов логического вывода и увеличение трудоемкости внесения изменений в базу знаний.
2. Затруднена обработка исключений. Наиболее эффективно применение подхода для предметной области, где родовые связи изменяются не часто и насчитывается небольшое число исключений.
3. Информация, представленная во фрейме, разрознена и не может быть выстроена в последовательность высказываний.
4. Отсутствует специальный механизм управления выводом, только на основе использования присоединенных процедур.


## 10. Задачи

- [Дана начальная популяция из четырех хромосом с двумя генами x и y. Найти максимальный показатель качества хромосомы в популяции и общее качество популяции после четырех этапов эволюции](http://vuz.exponenta.ru/PDF/book/bm63.pdf)

- Дана многослойная нейронная сеть, матрицы весовых коэффициентов связей

  вход: X (1x4), Y (1x2)

  веса: W1 (4x3), W2 (3, 2)

  активации: f1, f2

  лосс: L(X, Y)

  скорость обучения: lr

  forward: 
  ```
  A0 = X^T
  X1 = W1^T x A0   | (3, 1)
  A1 = f1(X1)   | (3, 1)
  X2 = W2^T x A1   | (2, 1)
  A2 = f2(X2)   | (2, 1)
  loss = L(A2, Y)   | (1)
  ```
  
  backward:
  ```
  E2 = dloss/dW2 = dloss/dA2 * df2/dX2   | (2, 1)
  E1 = dloss/dW1 = (W2 x E2) * df1/dX1   | (3, 1)
  
  dloss/dW2 = A1 x E2^T   | (3, 2)
  dloss/dW1 = A0 x E1^T   | (4, 3)

  W2 = W2 - lr * dloss/dW2
  W1 = W1 - lr * dloss/dW1
  ```

- [Найти наилучшее размещение графа на линейке после трех циклов генетического алгоритма](http://vuz.exponenta.ru/PDF/book/nnet72.pdf)

- [Найти длину гамильтонова цикла S в полном графе после четырех циклов решения задачи методом отжига](http://vuz.exponenta.ru/PDF/book/bm61.pdf)
